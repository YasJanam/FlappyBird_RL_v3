# FlappyBird_RL_v3
 "It’s recommended to run the code directly from the terminal (or CMD ...)."
تعداد پایپ ها: چند پایپ(multi-pipe)   

نوع اکشن : گسسته؛ از نوع بپر-نپر ( اکشن صرفا این است که پرنده بپرد یا نپرد؛ قدرت پرش پرنده، gravity,... ثابت هستند و از قبل تعیین میشوند.)  

الگوریتم به کار رفته : episodic actor-critic (بعد از هر اپیزود policy آپدیت میشود)  

محیط گرافیکی : بسیار ساده و ابتدایی( در حد نمایش گرافیکی)  

تغییرات اعمال شده بر روی ورژن ۲ : کلاس های RewardShaping , DoneManager برای محاسبه پاداش هر موقعیت و مدیریت پایان step پیاده شده اند ( در ورژن ۲ در کلاس environment یا همان محیط یادگیری تقویتی بودند.)
همچینین بازی چند پایپه شده است و فاصله پایپ ها از هم متفاوت و رندوم است.

نکته جالب : این دو نسخه(۲،۳) با اکشن گسستهِ باینری پیاده شده اند. اما اینکه اکشن چگونه باشد و چه باشد باعث تغییر در یادگیری عامل میشود. یک حالت دیگر این است که اکشن پیوسته و برابر قدرت پرش پرنده باشد( یعنی پرش نکن معادل میشه با پرش با قدرت پرش صفر)  
